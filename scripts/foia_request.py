#!/usr/bin/env python2

import requests
import unicodecsv
import hashlib
from curtsies import Input
import logging

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# create a file handler
handler = logging.FileHandler('hello.log')
handler.setLevel(logging.INFO)

# create a logging format
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)

# add the handlers to the logger
logger.addHandler(handler)

token = 'd0c2d39330ca78bdafae9c8d7f0dec284c3c8fc1'#get_api_key()
url = 'https://www.muckrock.com/api_v1/'

headers = {'Authorization': 'Token %s' % token, 'content-type': 'application/json'}


next_ = url + 'foia'

fields = (
    'id',
    'user',
    'title',
    'slug',
    'status',
#    'jurisdiction',
    'agency',
    'date_submitted',
    'date_done',
    'date_due',
    'days_until_due',
    'date_followup',
    'embargo',
    'date_embargo',
    'price',
    'description',
    'tracking_id',
    'tags'
)
fields_root  = ['id_key', 'id', 'title', 'slug', 'status', 'embargo', 'permanent_embargo', 'user', 'username', 'agency', 'date_due', 'days_until_due', 'date_followup', 'datetime_done', 'date_embargo', 'tracking_id', 'price', 'disable_autofollowups', 'tags', 'absolute_url']
fields_comm  = ['id_key', 'foia', 'from_user', 'to_user', 'subject', 'datetime', 'response', 'autogenerated', 'thanks', 'full_html', 'communication', 'status', 'likely_foia', 'delivered']
fields_file =  ['id_key', 'id', 'ffile', 'title', 'datetime', 'source', 'description','access','doc_id','pages']

# set page to control end point
page = 0

csv_file = open('foia_root.csv', 'wb')
csv_file.seek(0)
csv_writer = unicodecsv.writer(csv_file)
csv_writer.writerow(fields_root)

csv_file_comm = open('foia_comm.csv', 'wb')
csv_file_comm.seek(0)
csv_writer_comm = unicodecsv.writer(csv_file_comm)
csv_writer_comm.writerow(fields_comm)

csv_file_file = open('foia_file.csv', 'wb')
csv_file_file.seek(0)
csv_writer_file = unicodecsv.writer(csv_file_file)
csv_writer_file.writerow(fields_file)

while next_ is not None:

    r = requests.get(next_, headers=headers) 
    page += 1
    
    json = r.json() 
    next_ = json['next']
    for datum in json['results']:
        # index across tables
        id_key = datum['id']
        datum['id_key'] = id_key

        # main foia data
        csv_writer.writerow([datum[field] for field in fields_root])
        for comm in datum['communications']:
            comm['id_key'] = id_key
            # communication data
            csv_writer_comm.writerow([comm[field] for field in fields_comm])
            for file in comm['files']:
                # file data
                file['id_key'] = id_key
                csv_writer_file.writerow([file[field] for field in fields_file])

    print('Page %d of %d' % (page, json['count'] / 20 + 1))
    total_pages = json['count'] / 20 + 1
    logger.info(f'Page {page}/{total_pages} -- {next_}')

csv_file.close()
csv_file_comm.close()
csv_file_file.close()
exit()

