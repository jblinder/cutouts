"https://www.muckrock.com/api_v1/agency/"

#!/usr/bin/env python2

import requests
import unicodecsv
import hashlib
from curtsies import Input
from pymongo import MongoClient
from pymongo import InsertOne, DeleteOne, ReplaceOne
import logging

# setup mongo
client = MongoClient()
db = client.muckrock
print("original",db.collection_names())

#if 'agnecy' not in db.collection_names():
    #print("foia collection not found")
    #db.create_collection("agency")

agencies           = db.get_collection('agency')

print("new",db.collection_names())

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# create a file handler
handler = logging.FileHandler('agency.log')
handler.setLevel(logging.INFO)

# create a logging format
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)

# add the handlers to the logger
logger.addHandler(handler)

token = 'd0c2d39330ca78bdafae9c8d7f0dec284c3c8fc1'#get_api_key()
url = 'https://www.muckrock.com/api_v1/'

headers = {'Authorization': 'Token %s' % token, 'content-type': 'application/json'}


url = url + 'agency/?page='

fields = (
    'id',
    'user',
    'title',
    'slug',
    'status',
#    'jurisdiction',
    'agency',
    'date_submitted',
    'date_done',
    'date_due',
    'days_until_due',
    'date_followup',
    'embargo',
    'date_embargo',
    'price',
    'description',
    'tracking_id',
    'tags'
)
fields_root  = ['id', 'name', 'slug', 'status', 'exempt', 'types', 'requires_proxy', 'jurisdiction', 'location', 'website', 'twitter', 'twitter_handles', 'parent', 'appeal_agency', 'url', 'foia_logs', 'foia_guide', 'public_notes', 'absolute_url', 'average_response_time', 'fee_rate','success_rate']
#fields_comm  = ['id_key', 'foia', 'from_user', 'to_user', 'subject', 'datetime', 'response', 'autogenerated', 'thanks', 'full_html', 'communication', 'status', 'likely_foia', 'delivered']
#fields_file =  ['id_key', 'id', 'ffile', 'title', 'datetime', 'source', 'description','access','doc_id','pages']

# set page to control end point
page = 238

csv_file = open('foia_agency.csv', 'wb')
#csv_file.seek(0)
csv_writer = unicodecsv.writer(csv_file)
csv_writer.writerow(fields_root)

is_finished = False
while is_finished is False:

    req_url = url + str(page)

    try:
        r = requests.get(req_url, headers=headers) 
        json = r.json()
    except requests.exceptions.RequestException as e:  # This is the correct syntax
        print(e)
        print("exception")
        json = []

    if 'results' not in json:
        is_finished = True
        print("No results found")
        break

    for datum in json['results']:
        # clean commas
        for key, value in datum.items():
            if isinstance(value, str):
                datum[key] = value.replace(',',' ')

        # index across tables
        #id_key = datum['id']
        #datum['id_key'] = id_key
        agencies.insert_one(datum)
        # main foia data
        csv_writer.writerow([datum[field] for field in fields_root])
    
    print('Page %d of %d' % (page, json['count'] / 20 + 1))
    total_pages = json['count'] // 20 + 1
    logger.info(f'Page: {page} / {total_pages} Url: {req_url}')
    page += 1
    if page >= total_pages:
        total_pages = True

print("Closing CSVs...")
csv_file.close()
#csv_file_comm.close()
#csv_file_file.close()
print("Exiting")
exit()

